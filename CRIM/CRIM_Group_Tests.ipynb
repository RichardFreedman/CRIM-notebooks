{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crim_intervals import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib\n",
    "from itertools import tee, combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS DEV COPY for use with CLOSE/EXACT Matches\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Converts lists to tuples\n",
    "\n",
    "def lists_to_tuples_a(el):\n",
    "    if isinstance(el, list):\n",
    "        return tuple(el)\n",
    "    else:\n",
    "        return el\n",
    "\n",
    "# Filters for the length of the Presentation Type in the Classifier\n",
    "\n",
    "def limit_offset_size(array, limit):\n",
    "    under_limit = np.cumsum(array) <= limit\n",
    "    return array[: sum(under_limit)]\n",
    "\n",
    "# Gets the the list of offset differences for each group \n",
    "\n",
    "def get_offset_difference_list_a(group):\n",
    "    # if we do sort values as part of the func call, then we don't need this first line\n",
    "    group = group.sort_values(\"start_offset\")\n",
    "    group[\"next_offset\"] = group.start_offset.shift(-1)\n",
    "    offset_difference_list = (group.next_offset - group.start_offset).dropna().tolist()\n",
    "    return offset_difference_list\n",
    "\n",
    "# The classifications are done here\n",
    "\n",
    "def classify_offsets_a(offset_difference_list):\n",
    "    \"\"\"\n",
    "    Put logic for classifying an offset list here\n",
    "    \"\"\"\n",
    "    #\n",
    "    offset_difference_list = limit_offset_size(offset_difference_list, 40)\n",
    "    \n",
    "    alt_list = offset_difference_list[::2]\n",
    "    \n",
    "    if len(set(offset_difference_list)) == 1 and len(offset_difference_list) > 1:\n",
    "        return (\"PEN\", offset_difference_list)\n",
    "    # elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1):\n",
    "    elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1) and (len(offset_difference_list) >= 3):\n",
    "        return (\"ID\", offset_difference_list)\n",
    "    elif len(offset_difference_list) >= 1:\n",
    "        return (\"Fuga\", offset_difference_list)\n",
    "    else: \n",
    "        return (\"Singleton\", offset_difference_list)\n",
    "    \n",
    "# adds predicted type, offsets and entry numbers to the results\n",
    "\n",
    "def predict_type_a(group):\n",
    "    offset_differences = get_offset_difference_list_a(group)\n",
    "    predicted_type, offsets = classify_offsets_a(offset_differences)\n",
    "\n",
    "    group[\"predicted_type\"] = [predicted_type for i in range(len(group))]\n",
    "    group[\"offset_diffs\"] = [offsets for i in range(len(group))]\n",
    "    group[\"entry_number\"] = [i + 1 for i in range(len(group))]\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(('ave_test_set.csv'), index_col=0)\n",
    "df = df.drop(columns=[\"ema\", \"ema_url\", \"end_measure\", \"end_beat\"])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists for views.  These are used when calling the df below\n",
    "simple_view = [\"piece_title\", \"part\", \"pattern_generating_match\", \"pattern_matched\", \"start_offset\"]\n",
    "offset_details = [\"start_measure\", \"start_beat\", \"end_offset\", \"note_durations\", \"prev_entry_off\", \"next_entry_off\"]\n",
    "drop_cols = [\"pattern_matched\", \"part\", \"pattern_generating_match\", \"piece_title\", \"start_measure\", \"start_beat\", \"end_offset\", \"note_durations\", \"prev_entry_off\", \"next_entry_off\"]\n",
    "ready_classify = [\"pattern_generating_match\", \"pattern_matched\", \"piece_title\", \"part\", \"start_measure\", \"start_beat\", \"start_offset\", \"sum_durs\", \"sub_group_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    pattern_generating_match       pattern_matched piece_title        part  \\\n",
       "18      (-2, -2, -2, -2, -2)  [-2, -2, -2, -2, -2]   Ave Maria  [Superius]   \n",
       "19      (-2, -2, -2, -2, -2)  [-2, -2, -2, -2, -2]   Ave Maria  [Superius]   \n",
       "73      (-2, -2, -2, -2, -3)  [-2, -2, -2, -2, -3]   Ave Maria       Tenor   \n",
       "177      (-2, -2, -2, -2, 1)   [-2, -2, -2, -2, 1]   Ave Maria       Altus   \n",
       "176      (-2, -2, -2, -2, 1)   [-2, -2, -2, -2, 1]   Ave Maria  [Superius]   \n",
       "\n",
       "     start_measure  start_beat  start_offset  end_offset  \\\n",
       "18              19         1.0         144.0       156.0   \n",
       "19              20         4.0         158.0       172.0   \n",
       "73              42         1.0         328.0       348.0   \n",
       "177             95         1.0         756.0       776.0   \n",
       "176            104         1.0         864.0       884.0   \n",
       "\n",
       "                     note_durations  sum_durs  ...  next_entry_off  is_first  \\\n",
       "18   [3.0, 1.0, 2.0, 2.0, 4.0, 2.0]      14.0  ...           158.0      True   \n",
       "19   [3.0, 1.0, 4.0, 2.0, 4.0, 4.0]      18.0  ...           216.0     False   \n",
       "73   [6.0, 2.0, 4.0, 4.0, 4.0, 2.0]      22.0  ...           328.0      True   \n",
       "177  [6.0, 2.0, 2.0, 2.0, 8.0, 4.0]      24.0  ...           804.0      True   \n",
       "176  [6.0, 2.0, 2.0, 2.0, 8.0, 4.0]      24.0  ...           872.0     False   \n",
       "\n",
       "     is_last  last_off_diff  next_off_diff  parallel  forward_gapped  \\\n",
       "18     False            NaN           14.0     False           False   \n",
       "19     False           14.0           58.0     False            True   \n",
       "73     False          344.0            0.0     False           False   \n",
       "177    False          132.0           48.0     False            True   \n",
       "176    False           60.0            8.0     False           False   \n",
       "\n",
       "     back_gapped  singleton  split_group  \n",
       "18         False      False        False  \n",
       "19         False      False        False  \n",
       "73         False      False        False  \n",
       "177        False      False        False  \n",
       "176         True      False         True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pattern_generating_match</th>\n      <th>pattern_matched</th>\n      <th>piece_title</th>\n      <th>part</th>\n      <th>start_measure</th>\n      <th>start_beat</th>\n      <th>start_offset</th>\n      <th>end_offset</th>\n      <th>note_durations</th>\n      <th>sum_durs</th>\n      <th>...</th>\n      <th>next_entry_off</th>\n      <th>is_first</th>\n      <th>is_last</th>\n      <th>last_off_diff</th>\n      <th>next_off_diff</th>\n      <th>parallel</th>\n      <th>forward_gapped</th>\n      <th>back_gapped</th>\n      <th>singleton</th>\n      <th>split_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>(-2, -2, -2, -2, -2)</td>\n      <td>[-2, -2, -2, -2, -2]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>19</td>\n      <td>1.0</td>\n      <td>144.0</td>\n      <td>156.0</td>\n      <td>[3.0, 1.0, 2.0, 2.0, 4.0, 2.0]</td>\n      <td>14.0</td>\n      <td>...</td>\n      <td>158.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(-2, -2, -2, -2, -2)</td>\n      <td>[-2, -2, -2, -2, -2]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>20</td>\n      <td>4.0</td>\n      <td>158.0</td>\n      <td>172.0</td>\n      <td>[3.0, 1.0, 4.0, 2.0, 4.0, 4.0]</td>\n      <td>18.0</td>\n      <td>...</td>\n      <td>216.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>14.0</td>\n      <td>58.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>(-2, -2, -2, -2, -3)</td>\n      <td>[-2, -2, -2, -2, -3]</td>\n      <td>Ave Maria</td>\n      <td>Tenor</td>\n      <td>42</td>\n      <td>1.0</td>\n      <td>328.0</td>\n      <td>348.0</td>\n      <td>[6.0, 2.0, 4.0, 4.0, 4.0, 2.0]</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>328.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>344.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>(-2, -2, -2, -2, 1)</td>\n      <td>[-2, -2, -2, -2, 1]</td>\n      <td>Ave Maria</td>\n      <td>Altus</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>756.0</td>\n      <td>776.0</td>\n      <td>[6.0, 2.0, 2.0, 2.0, 8.0, 4.0]</td>\n      <td>24.0</td>\n      <td>...</td>\n      <td>804.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>132.0</td>\n      <td>48.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>(-2, -2, -2, -2, 1)</td>\n      <td>[-2, -2, -2, -2, 1]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>104</td>\n      <td>1.0</td>\n      <td>864.0</td>\n      <td>884.0</td>\n      <td>[6.0, 2.0, 2.0, 2.0, 8.0, 4.0]</td>\n      <td>24.0</td>\n      <td>...</td>\n      <td>872.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>60.0</td>\n      <td>8.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# now process the original match data df by:\n",
    "# sorting by start offset, then group by pattern generating match and applying the function above for prev entry\n",
    "# also give each group a number\n",
    "# sort by group number and start offset\n",
    "# so that we can find PARALLEL (=0) Forward Gaps (the distance to NEXT entry), and Backward Gaps (distance to PREVIOUS Entry)\n",
    "# All Proximate Matches are part of same sub Group (and go to classifier)\n",
    "# Parallels are part of Sub Group but NOT part of Classified.  We will filter them OUT before classification\n",
    "# Forward ONLY means the NEXT entry is a GAP.  No problem for Forward ONLY, since these are part of the previous set.\n",
    "# Backward ONLY means the LAST entry was a GAP.  So these are NEW subgroups, since a new Presentation Type begins\n",
    "# Forward AND Backward Gaps are SINGLETONS:  We will filter then OUT before Classification\n",
    "# If an entry is the LAST in a Group and also has a BACKWARD gap it is also a SINGLETON\n",
    "\n",
    "df2 = df.sort_values(\"start_offset\")\n",
    "df2[\"group_number\"] = df2.groupby('pattern_generating_match').ngroup()\n",
    "df2 = df2.sort_values(['group_number', 'start_offset'])\n",
    "df2[\"prev_entry_off\"] = df2[\"start_offset\"].shift(1)\n",
    "df2[\"next_entry_off\"] = df2[\"start_offset\"].shift(-1)\n",
    "y = df2.drop_duplicates(subset=[\"pattern_matched\"], keep='first').index\n",
    "df2[\"is_first\"] = df2.index.isin(y)\n",
    "z = df2.drop_duplicates(subset=[\"pattern_matched\"], keep='last').index\n",
    "df2[\"is_last\"] = df2.index.isin(z)\n",
    "df2[\"last_off_diff\"] = df2[\"start_offset\"] - df2[\"prev_entry_off\"]\n",
    "df2[\"next_off_diff\"] = df2[\"next_entry_off\"] - df2[\"start_offset\"]\n",
    "df2[\"parallel\"] = df2[\"last_off_diff\"] == 0\n",
    "df2[\"forward_gapped\"] = df2[\"next_off_diff\"] >= 20\n",
    "df2[\"back_gapped\"] = df2[\"last_off_diff\"] >= 20\n",
    "df2[\"singleton\"] = ((df2['forward_gapped'] == True) & (df2['back_gapped'] == True) | (df2['back_gapped'] == True) & (df2[\"is_last\"]))\n",
    "df2[\"split_group\"] = (df2['forward_gapped'] == False) & (df2['back_gapped'] == True)\n",
    "\n",
    "\n",
    "#now mask out Parallels and Singletons\n",
    "df2 = df2[df2[\"parallel\"] != True]\n",
    "df2 = df2[df2[\"singleton\"] != True]\n",
    "df2[\"next_off_diff\"] = df2[\"next_off_diff\"].abs()\n",
    "df2[\"last_off_diff\"] = df2[\"last_off_diff\"].abs()\n",
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    pattern_generating_match       pattern_matched piece_title        part  \\\n",
       "18      (-2, -2, -2, -2, -2)  [-2, -2, -2, -2, -2]   Ave Maria  [Superius]   \n",
       "19      (-2, -2, -2, -2, -2)  [-2, -2, -2, -2, -2]   Ave Maria  [Superius]   \n",
       "73      (-2, -2, -2, -2, -3)  [-2, -2, -2, -2, -3]   Ave Maria       Tenor   \n",
       "177      (-2, -2, -2, -2, 1)   [-2, -2, -2, -2, 1]   Ave Maria       Altus   \n",
       "176      (-2, -2, -2, -2, 1)   [-2, -2, -2, -2, 1]   Ave Maria  [Superius]   \n",
       "\n",
       "     start_measure  start_beat  start_offset  end_offset  \\\n",
       "18              19         1.0         144.0       156.0   \n",
       "19              20         4.0         158.0       172.0   \n",
       "73              42         1.0         328.0       348.0   \n",
       "177             95         1.0         756.0       776.0   \n",
       "176            104         1.0         864.0       884.0   \n",
       "\n",
       "                     note_durations  sum_durs  ...  is_last  last_off_diff  \\\n",
       "18   [3.0, 1.0, 2.0, 2.0, 4.0, 2.0]      14.0  ...    False            NaN   \n",
       "19   [3.0, 1.0, 4.0, 2.0, 4.0, 4.0]      18.0  ...    False           14.0   \n",
       "73   [6.0, 2.0, 4.0, 4.0, 4.0, 2.0]      22.0  ...    False          344.0   \n",
       "177  [6.0, 2.0, 2.0, 2.0, 8.0, 4.0]      24.0  ...    False          132.0   \n",
       "176  [6.0, 2.0, 2.0, 2.0, 8.0, 4.0]      24.0  ...    False           60.0   \n",
       "\n",
       "     next_off_diff  parallel  forward_gapped  back_gapped  singleton  \\\n",
       "18            14.0     False           False        False      False   \n",
       "19            58.0     False            True        False      False   \n",
       "73             0.0     False           False        False      False   \n",
       "177           48.0     False            True        False      False   \n",
       "176            8.0     False           False         True      False   \n",
       "\n",
       "     split_group  combined_group  sub_group_id  \n",
       "18         False            True           0.0  \n",
       "19         False           False           0.0  \n",
       "73         False            True           1.0  \n",
       "177        False            True           2.0  \n",
       "176         True            True           3.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pattern_generating_match</th>\n      <th>pattern_matched</th>\n      <th>piece_title</th>\n      <th>part</th>\n      <th>start_measure</th>\n      <th>start_beat</th>\n      <th>start_offset</th>\n      <th>end_offset</th>\n      <th>note_durations</th>\n      <th>sum_durs</th>\n      <th>...</th>\n      <th>is_last</th>\n      <th>last_off_diff</th>\n      <th>next_off_diff</th>\n      <th>parallel</th>\n      <th>forward_gapped</th>\n      <th>back_gapped</th>\n      <th>singleton</th>\n      <th>split_group</th>\n      <th>combined_group</th>\n      <th>sub_group_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>(-2, -2, -2, -2, -2)</td>\n      <td>[-2, -2, -2, -2, -2]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>19</td>\n      <td>1.0</td>\n      <td>144.0</td>\n      <td>156.0</td>\n      <td>[3.0, 1.0, 2.0, 2.0, 4.0, 2.0]</td>\n      <td>14.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(-2, -2, -2, -2, -2)</td>\n      <td>[-2, -2, -2, -2, -2]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>20</td>\n      <td>4.0</td>\n      <td>158.0</td>\n      <td>172.0</td>\n      <td>[3.0, 1.0, 4.0, 2.0, 4.0, 4.0]</td>\n      <td>18.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>14.0</td>\n      <td>58.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>(-2, -2, -2, -2, -3)</td>\n      <td>[-2, -2, -2, -2, -3]</td>\n      <td>Ave Maria</td>\n      <td>Tenor</td>\n      <td>42</td>\n      <td>1.0</td>\n      <td>328.0</td>\n      <td>348.0</td>\n      <td>[6.0, 2.0, 4.0, 4.0, 4.0, 2.0]</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>344.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>(-2, -2, -2, -2, 1)</td>\n      <td>[-2, -2, -2, -2, 1]</td>\n      <td>Ave Maria</td>\n      <td>Altus</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>756.0</td>\n      <td>776.0</td>\n      <td>[6.0, 2.0, 2.0, 2.0, 8.0, 4.0]</td>\n      <td>24.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>132.0</td>\n      <td>48.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>(-2, -2, -2, -2, 1)</td>\n      <td>[-2, -2, -2, -2, 1]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>104</td>\n      <td>1.0</td>\n      <td>864.0</td>\n      <td>884.0</td>\n      <td>[6.0, 2.0, 2.0, 2.0, 8.0, 4.0]</td>\n      <td>24.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>60.0</td>\n      <td>8.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "\n",
    "df2[\"combined_group\"] = (df2.split_group | df2.is_first)\n",
    "df2.loc[(df2[\"combined_group\"]), \"sub_group_id\"] = range(df2.combined_group.sum())\n",
    "df2[\"sub_group_id\"] = df2[\"sub_group_id\"].ffill()\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    pattern_generating_match       pattern_matched piece_title        part  \\\n",
       "18      (-2, -2, -2, -2, -2)  [-2, -2, -2, -2, -2]   Ave Maria  [Superius]   \n",
       "19      (-2, -2, -2, -2, -2)  [-2, -2, -2, -2, -2]   Ave Maria  [Superius]   \n",
       "73      (-2, -2, -2, -2, -3)  [-2, -2, -2, -2, -3]   Ave Maria       Tenor   \n",
       "177      (-2, -2, -2, -2, 1)   [-2, -2, -2, -2, 1]   Ave Maria       Altus   \n",
       "176      (-2, -2, -2, -2, 1)   [-2, -2, -2, -2, 1]   Ave Maria  [Superius]   \n",
       "\n",
       "     start_measure  start_beat  start_offset  sum_durs  sub_group_id  \n",
       "18              19         1.0         144.0      14.0           0.0  \n",
       "19              20         4.0         158.0      18.0           0.0  \n",
       "73              42         1.0         328.0      22.0           1.0  \n",
       "177             95         1.0         756.0      24.0           2.0  \n",
       "176            104         1.0         864.0      24.0           3.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pattern_generating_match</th>\n      <th>pattern_matched</th>\n      <th>piece_title</th>\n      <th>part</th>\n      <th>start_measure</th>\n      <th>start_beat</th>\n      <th>start_offset</th>\n      <th>sum_durs</th>\n      <th>sub_group_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>(-2, -2, -2, -2, -2)</td>\n      <td>[-2, -2, -2, -2, -2]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>19</td>\n      <td>1.0</td>\n      <td>144.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(-2, -2, -2, -2, -2)</td>\n      <td>[-2, -2, -2, -2, -2]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>20</td>\n      <td>4.0</td>\n      <td>158.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>(-2, -2, -2, -2, -3)</td>\n      <td>[-2, -2, -2, -2, -3]</td>\n      <td>Ave Maria</td>\n      <td>Tenor</td>\n      <td>42</td>\n      <td>1.0</td>\n      <td>328.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>(-2, -2, -2, -2, 1)</td>\n      <td>[-2, -2, -2, -2, 1]</td>\n      <td>Ave Maria</td>\n      <td>Altus</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>756.0</td>\n      <td>24.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>(-2, -2, -2, -2, 1)</td>\n      <td>[-2, -2, -2, -2, 1]</td>\n      <td>Ave Maria</td>\n      <td>[Superius]</td>\n      <td>104</td>\n      <td>1.0</td>\n      <td>864.0</td>\n      <td>24.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "df3 = df2[ready_classify]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified2 = df3.applymap(lists_to_tuples_a).groupby(\"sub_group_id\").apply(predict_type_a)\n",
    "classified2.drop(classified2[classified2['predicted_type'] == \"Singleton\"].index, inplace = True)\n",
    "\n",
    "# classified2 = classified2[classified2[\"predicted_type\"] == \"ID\"]\n",
    "\n",
    "classified2.head(50)\n",
    "classified2.to_csv('test2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = df.applymap(lists_to_tuples_a).sort_values(\"start_offset\").groupby(\"sub_group_id\").apply(predict_type_a)\n",
    "classified[\"group_number\"] = classified.groupby('pattern_generating_match').ngroup()\n",
    "classified = classified[[\"group_number\", \"pattern_generating_match\", \"pattern_matched\", \"part\", \"start_measure\", \"start_beat\", \"entry_number\", \"start_offset\", \"sum_durs\", \"offset_diffs\", \"predicted_type\"]]\n",
    "\n",
    "# remove singleton entries\n",
    "\n",
    "classified.drop(classified[classified['predicted_type'] == \"Singleton\"].index, inplace = True)\n",
    "\n",
    "# now classified results, in order by OFFSET and ENTRY NUMBER, but the group numbers can overlap with each other.\n",
    "classified.head(25)\n",
    "\n",
    "classified = classified.sort_values([\"group_number\", \"entry_number\"])\n",
    "classified= classified[[\"group_number\", \"entry_number\", \"pattern_matched\", \"part\", \"start_measure\", \"start_beat\", \"start_offset\", \"sum_durs\", \"offset_diffs\", \"predicted_type\"]]\n",
    "classified[\"offset_list_length\"] = classified[\"offset_diffs\"].apply(len) + 1\n",
    "classified.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df3.groupby(\"group_number\"):\n",
    "    df3.loc[df3.split_group, \"subgroup_id\"] = range(1, df3.split_group.sum() + 1)\n",
    "df3.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2.split_group, \"new_subgroup_id\"] = range(2, df2.split_group.sum() + 2)\n",
    "\n",
    "df2[\"new_subgroup_id\"] = df2[\"new_subgroup_id\"].ffill().fillna(1)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we need to interate over each group in order to split the groups at wherever \"split_group\" is TRUE\n",
    "# # initalize sub-group counter\n",
    "sub_counter = 0\n",
    "\n",
    "# the split-group column tells us if we need to start a new sub-group for that set of matches\n",
    "# if TRUE, then we need to add a new sub_group_number\n",
    "# if FALSE, then sub_group is the same\n",
    "for name, group in df2.groupby(\"group_number\"):\n",
    "    if df2[\"split_group\"] is False:\n",
    "        df2[\"sub_group_id\"] = sub_counter   \n",
    "    else:\n",
    "        sub_counter = sub_counter + 1\n",
    "        df2[\"sub_group_id\"] = sub_counter\n",
    "\n",
    "df2.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = classified[classified.entry_number <= classified.offset_list_length]\n",
    "classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classify = df.sort_values(\"start_offset\").groupby(\"pattern_matched\")\n",
    "for pattern_matched, group in classify: \n",
    "    classify[\"prev_ent_offset\"] = classify[\"start_offset\"]\n",
    "    print(prev_ent_offset) \n",
    "    # print(group) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run the classifer, but on DF from which the Parallel Entries have been removed!\n",
    "\n",
    "classified2 = df3.applymap(lists_to_tuples_a).sort_values(\"start_offset\").groupby(\"pattern_matched\").apply(predict_type_a)\n",
    "classified2[\"group_number\"] = classified2.groupby('pattern_generating_match').ngroup()\n",
    "classified2 = classified2[[\"group_number\", \"pattern_generating_match\", \"pattern_matched\", \"part\", \"start_measure\", \"start_beat\", \"entry_number\", \"start_offset\", \"prev_entry_off\",\"sum_durs\", \"offset_diffs\", \"predicted_type\"]]\n",
    "\n",
    "# remove singleton entries\n",
    "\n",
    "# classified2.drop(classified[classified['predicted_type'] == \"Singleton\"].index, inplace = True)\n",
    "\n",
    "# now classified results, in order by OFFSET and ENTRY NUMBER, but the group numbers can overlap with each other.\n",
    "\n",
    "classified2 = classified2.sort_values([\"group_number\", \"entry_number\"])\n",
    "classified2= classified2[[\"group_number\", \"entry_number\", \"pattern_matched\", \"part\", \"start_measure\", \"start_beat\", \"start_offset\", \"prev_entry_off\", \"sum_durs\", \"offset_diffs\", \"predicted_type\"]]\n",
    "# classified2 = classified2[classified2[\"predicted_type\"] == \"PEN\"]\n",
    "\n",
    "classified2.head()"
   ]
  }
 ]
}
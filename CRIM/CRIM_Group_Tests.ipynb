{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crim_intervals import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib\n",
    "from itertools import tee, combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS DEV COPY for use with CLOSE/EXACT Matches\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Converts lists to tuples\n",
    "\n",
    "def lists_to_tuples_a(el):\n",
    "    if isinstance(el, list):\n",
    "        return tuple(el)\n",
    "    else:\n",
    "        return el\n",
    "\n",
    "# Filters for the length of the Presentation Type in the Classifier\n",
    "\n",
    "def limit_offset_size(array, limit):\n",
    "    under_limit = np.cumsum(array) <= limit\n",
    "    return array[: sum(under_limit)]\n",
    "\n",
    "# Gets the the list of offset differences for each group \n",
    "\n",
    "def get_offset_difference_list_a(group):\n",
    "    # if we do sort values as part of the func call, then we don't need this first line\n",
    "    group = group.sort_values(\"start_offset\")\n",
    "    group[\"next_offset\"] = group.start_offset.shift(-1)\n",
    "    offset_difference_list = (group.next_offset - group.start_offset).dropna().tolist()\n",
    "    return offset_difference_list\n",
    "\n",
    "# The classifications are done here\n",
    "# be sure to have the offset difference limit set here and matched in gap check below  80 = ten bars\n",
    "\n",
    "def classify_offsets_a(offset_difference_list):\n",
    "    \"\"\"\n",
    "    Put logic for classifying an offset list here\n",
    "    \"\"\"\n",
    "    # \n",
    "    offset_difference_list = limit_offset_size(offset_difference_list, 500)\n",
    "    \n",
    "    alt_list = offset_difference_list[::2]\n",
    "    \n",
    "    if len(set(offset_difference_list)) == 1 and len(offset_difference_list) > 1:\n",
    "        return (\"PEN\", offset_difference_list)\n",
    "    # elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1):\n",
    "    elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1) and (len(offset_difference_list) >= 3):\n",
    "        return (\"ID\", offset_difference_list)\n",
    "    elif len(offset_difference_list) >= 1:\n",
    "        return (\"Fuga\", offset_difference_list)\n",
    "    else: \n",
    "        return (\"Singleton\", offset_difference_list)\n",
    "    \n",
    "# adds predicted type, offsets and entry numbers to the results\n",
    "\n",
    "def predict_type_a(group):\n",
    "    offset_differences = get_offset_difference_list_a(group)\n",
    "    predicted_type, offsets = classify_offsets_a(offset_differences)\n",
    "\n",
    "    group[\"predicted_type\"] = [predicted_type for i in range(len(group))]\n",
    "    group[\"offset_diffs\"] = [offsets for i in range(len(group))]\n",
    "    group[\"entry_number\"] = [i + 1 for i in range(len(group))]\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 614 entries, 0 to 613\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   pattern_generating_match  614 non-null    object\n",
      " 1   pattern_matched           614 non-null    object\n",
      " 2   piece_title               614 non-null    object\n",
      " 3   part                      614 non-null    object\n",
      " 4   start_measure             614 non-null    int64 \n",
      " 5   start_beat                614 non-null    object\n",
      " 6   start_offset              614 non-null    object\n",
      " 7   end_offset                614 non-null    object\n",
      " 8   note_durations            614 non-null    object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 48.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# read CSV output of CRIM Intervals Search.\n",
    "\n",
    "df = pd.read_csv(('A_Test_Files/Gombert_Super_Exact_4_3.csv'), index_col=0)\n",
    "df = df.drop(columns=[\"ema\", \"ema_url\", \"end_measure\", \"end_beat\"])\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists for views.  These are used when calling the df below\n",
    "\n",
    "simple_view = [\"piece_title\", \"part\", \"pattern_generating_match\", \"pattern_matched\", \"start_offset\"]\n",
    "\n",
    "offset_details = [\"start_measure\", \"start_beat\", \"end_offset\", \"note_durations\", \"prev_entry_off\", \"next_entry_off\"]\n",
    "\n",
    "drop_cols = [\"pattern_matched\", \"part\", \"pattern_generating_match\", \"piece_title\", \"start_measure\", \"start_beat\", \"end_offset\", \"note_durations\", \"prev_entry_off\", \"next_entry_off\"]\n",
    "\n",
    "ready_classify = [\"pattern_generating_match\", \"pattern_matched\", \"piece_title\", \"part\", \"start_measure\", \"start_beat\", \"start_offset\", \"sub_group_id\", \"is_first\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: <_ast.Call object at 0x7fe271b985e0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d0d2c54acfbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'note_durations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnote_durations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sum_durs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnote_durations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ast.py\u001b[0m in \u001b[0;36m_raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mnode_or_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_or_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'malformed node or string: {node!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: <_ast.Call object at 0x7fe271b985e0>"
     ]
    }
   ],
   "source": [
    "df['note_durations'] = df.note_durations.apply(ast.literal_eval)\n",
    "df[\"sum_durs\"] = df.note_durations.apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now process the original match data df by:\n",
    "# sorting by start offset, then group by pattern generating match and applying the function above for prev entry\n",
    "# also give each group a number\n",
    "# sort by group number and start offset\n",
    "# so that we can find PARALLEL (=0) Forward Gaps (the distance to NEXT entry), and Backward Gaps (distance to PREVIOUS Entry)\n",
    "# All Proximate Matches are part of same sub Group (and go to classifier)\n",
    "# Parallels are part of Sub Group but NOT part of Classified.  We will filter them OUT before classification\n",
    "# Forward ONLY means the NEXT entry is a GAP.  No problem for Forward ONLY, since these are part of the previous set.\n",
    "# Backward ONLY means the LAST entry was a GAP.  So these are NEW subgroups, since a new Presentation Type begins\n",
    "# Forward AND Backward Gaps are SINGLETONS:  We will filter then OUT before Classification\n",
    "# If an entry is the LAST in a Group and also has a BACKWARD gap it is also a SINGLETON\n",
    "\n",
    "df2 = df\n",
    "\n",
    "# Make Groups, Sort By Group and Offset, then and Add Previous/Next\n",
    "df2[\"group_number\"] = df2.groupby('pattern_matched').ngroup()\n",
    "df2 = df2.sort_values(['group_number', 'start_offset'])\n",
    "df2[\"prev_entry_off\"] = df2[\"start_offset\"].shift(1)\n",
    "df2[\"next_entry_off\"] = df2[\"start_offset\"].shift(-1)\n",
    "\n",
    "\n",
    "first_of_group = df2.drop_duplicates(subset=[\"pattern_matched\"], keep='first').index\n",
    "df2[\"is_first\"] = df2.index.isin(first_of_group)\n",
    "last_of_group = df2.drop_duplicates(subset=[\"pattern_matched\"], keep='last').index\n",
    "df2[\"is_last\"] = df2.index.isin(last_of_group)\n",
    "\n",
    "# Check Differences between Next and Last Offset\n",
    "\n",
    "df2[\"last_off_diff\"] = df2[\"start_offset\"] - df2[\"prev_entry_off\"]\n",
    "df2[\"next_off_diff\"] = df2[\"next_entry_off\"] - df2[\"start_offset\"]\n",
    "\n",
    "# Find Parallel Entries \n",
    "df2[\"parallel\"] = df2[\"last_off_diff\"] == 0\n",
    "\n",
    "# Set Gap Limits and Check Gaps Forward and Back\n",
    "df2[\"forward_gapped\"] = df2[\"next_off_diff\"] >= 50\n",
    "df2[\"back_gapped\"] = df2[\"last_off_diff\"] >= 50\n",
    "\n",
    "# Find Singletons and Split Groups with Gaps\n",
    "df2[\"singleton\"] = ((df2['forward_gapped'] == True) & (df2['back_gapped'] == True) | (df2['back_gapped'] == True) & (df2[\"is_last\"]))\n",
    "df2[\"split_group\"] = (df2['forward_gapped'] == False) & (df2['back_gapped'] == True)\n",
    "\n",
    "#Mask Out Parallels and Singletons\n",
    "df2 = df2[df2[\"parallel\"] != True]\n",
    "df2 = df2[df2[\"singleton\"] != True]\n",
    "df2[\"next_off_diff\"] = df2[\"next_off_diff\"].abs()\n",
    "df2[\"last_off_diff\"] = df2[\"last_off_diff\"].abs()\n",
    "\n",
    "# Find Final Groups\n",
    "df2[\"combined_group\"] = (df2.split_group | df2.is_first)\n",
    "df2.loc[(df2[\"combined_group\"]), \"sub_group_id\"] = range(df2.combined_group.sum())\n",
    "df2[\"sub_group_id\"] = df2[\"sub_group_id\"].ffill()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sum_durs.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask out short soggetti\n",
    "\n",
    "df2 = df2[df2[\"sum_durs\"] >= 15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact view for inspection of relevant columns\n",
    "\n",
    "df3 = df2[ready_classify]\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the classifier on the newly curated list of groups\n",
    "\n",
    "classified2 = df3.applymap(lists_to_tuples_a).groupby(\"sub_group_id\").apply(predict_type_a)\n",
    "\n",
    "# drop the new singletons\n",
    "\n",
    "# classified2.drop(classified2[classified2['predicted_type'] == \"Singleton\"].index, inplace = True)\n",
    "\n",
    "# classified2 = classified2[classified2[\"predicted_type\"] == \"Fuga\"]\n",
    "\n",
    "classified2[\"start\"] = classified2[\"start_measure\"].astype(str) +\"/\"+ classified2[\"start_beat\"].astype(str) \n",
    "classified2.drop(columns=['start_measure', 'start_beat','offset_diffs'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put things back in order by offset and group them again\n",
    "\n",
    "classified2.sort_values(by = [\"start_offset\"], inplace=True)\n",
    "c3 = classified2.groupby(by = [\"sub_group_id\"])\n",
    "c3 = c3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now transform as Pivot Table\n",
    "pivot_c3 = c3.pivot_table(index=[\"piece_title\", \"pattern_matched\", \"predicted_type\", \"sub_group_id\"],\n",
    "            columns=\"entry_number\",\n",
    "            values=[\"part\", \"start_offset\", \"start\"],\n",
    "            aggfunc=lambda x: x)\n",
    "pivot_c3_sort = pivot_c3.sort_values(by = [(\"start_offset\", 1)])\n",
    "pivot_c3_sort = pivot_c3_sort.fillna(\"-\")\n",
    "pivot_c3_sort.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_c3_sort.reset_index(inplace=True)\n",
    "pivot_c3_sort = pivot_c3_sort.drop(columns=['start_offset', \"sub_group_id\"])\n",
    "pivot_c3_sort.head(50)\n",
    "# pivot_c3.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
